/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package kibana_ingestion;

import co.elastic.clients.elasticsearch.ElasticsearchClient;
import co.elastic.clients.json.jackson.JacksonJsonpMapper;
import co.elastic.clients.transport.ElasticsearchTransport;
import co.elastic.clients.transport.rest_client.RestClientTransport;
import co.elastic.clients.util.DateTime;
import org.apache.http.HttpHost;
import org.apache.http.client.config.RequestConfig;
import org.elasticsearch.client.RestClient;
import org.elasticsearch.client.RestClientBuilder;
import org.json.simple.JSONArray;
import org.json.simple.JSONObject;
import org.json.simple.parser.JSONParser;

import java.io.FileReader;;
import java.sql.Timestamp;

import java.time.LocalDateTime;
import java.util.Iterator;

public class IngestionService implements Runnable{
    private static Integer thCount= 0;
    //Modify total batches to 60 inorder to run the code for 60 min, and for continous push of 10,000 records per min totalling to 6,00,000 records.
     private Integer totalBatches = 3;
     static Integer totalThreads = 0;
    private String elasticIndex = "j100";
     static Integer batchRecordsLen =0;
    static Integer entireRecordsLen = 0;
     static Object[] myTestData;
    Integer batchNo = 0;
    private int maxElapsedTime = 60;
    private ElasticsearchClient client = null;
    private RestClient restClient = null;
    private ElasticsearchTransport transport = null;

    @SuppressWarnings("unchecked")
    private void establishElasticSearchConnection(){

        RestClientBuilder builder = RestClient.builder(
                        new HttpHost("localhost", 9200))
                .setRequestConfigCallback(
                        new RestClientBuilder.RequestConfigCallback() {
                            @Override
                            public RequestConfig.Builder customizeRequestConfig(
                                    RequestConfig.Builder requestConfigBuilder) {
                                return requestConfigBuilder
                                        .setConnectTimeout(5000)
                                        .setSocketTimeout(60000);
                            }
                        });
        restClient = builder.build();
        // Create the transport with a Jackson mapper
        transport = new RestClientTransport(restClient, new JacksonJsonpMapper());
        // And create the API client
        client = new ElasticsearchClient(transport);

    }
    public void ingestRecordsInElasticSearch(int startIndex, int endIndex) throws Exception {

        int recordsProcessed=0;
        long startTime,endTime,elapsedTime=0;
        startTime=System.currentTimeMillis();
        int chunk = endIndex - startIndex;

        for(int i=startIndex;i<endIndex;i++) {

            Timestamp timestamp = new Timestamp(System.currentTimeMillis());

            if (elapsedTime < maxElapsedTime) {
                JSONObject record = (JSONObject) myTestData[i];
                String eventdt_str = timestamp.toString();
                record.put("EventDate", eventdt_str);
                if (recordsProcessed < chunk) {
                    client.index(idx->idx.index(elasticIndex).document(record));
                    recordsProcessed++;
                }
                else{
                    Thread.sleep((maxElapsedTime-elapsedTime)*1000);
                }
                    endTime = System.currentTimeMillis() - startTime;
                    elapsedTime = (long) Math.floor(endTime / 1000);
            } else {
               // System.out.println(recordsProcessed+" Records Processed out of the"+(endIndex-startIndex)+" Chunk Alloted:" );
                //System.out.println("ElapsedTime:"+elapsedTime);
                //Reset to default values
                startTime = System.currentTimeMillis();
                recordsProcessed = 0;
                elapsedTime = 0;
            }
        }
    }
    @Override
    public void run() {
        try{
            synchronized(thCount){
                thCount += 1;
                int thId = thCount;

               // System.out.println("New thread #"+thId);
                //Make the connection only once for each thread//~ total threads 80, so total of 80 connections
                establishElasticSearchConnection();
                int chunk = IngestionService.batchRecordsLen/totalThreads; //~125records per thread per 1min batch of 10,000
                while(batchNo < totalBatches){
                    int startIndex = (batchNo*IngestionService.batchRecordsLen)+((thId-1)*chunk);
                    int endIndex =  (batchNo*IngestionService.batchRecordsLen)+(thId*chunk);
                    ingestRecordsInElasticSearch(startIndex,endIndex);
                    batchNo++;
                }
            }
        }
        catch(Exception ex){
            ex.printStackTrace();
        }
    }
}

